defaults:
  - override /model_cfg@_global_: qwen3_8b
  - override /data_cfg@_global_: teacher_bespoke_stratos
  - override /trainer_cfg@_global_: teacher_grpo
  - _self_

# Use your SFT checkpoint from epoch 5
model_name_or_path: /home/user/trl/RLT/results/pre_rl_model_qwen3_7k/checkpoint-2190

bf16: true

# Training parameters
max_steps: 125
num_train_epochs: 1.0

save_strategy: "steps"
save_steps: 25
do_eval: true
save_final_model: true

eval_strategy: steps
eval_steps: 4

logging_steps: 1
logging_strategy: steps

# Batch size configuration
train_batch_size: 512  # Reduced from 1024 due to 32B student model memory needs
per_device_train_batch_size: 1  # Same as teacher_rlt.yaml for safety (3 GPUs Ã— 1 = 3)

# Generation parameters
num_generations: 24  # Reduced from 64 to fit 32B model in memory while maintaining quality
temperature: 0.7
unbias_log_probabilities: true

# GRPO specific parameters
learning_rate: 0.000001
beta: 0.04

# Reference model sync
sync_ref_model: true
ref_model_mixup_alpha: 0.9
ref_model_sync_steps: 32

# Student model for evaluation
student_model: "bespokelabs/Bespoke-Stratos-32B"
student_model_init_kwargs: null

offload_untrained_models: true

# Context windows
max_prompt_length: 16384
max_completion_length: 16384
# Generation settings are handled in trainer config

# Reward coefficients
answer_log_prob_coeff: [1, 0.01]
kl_penalty_reward_coeff: [3, 0.03]
normalize_log_prob_fn: null
clip_log_prob: 100000
normalize_kl_fn: null
clip_kl: 100000
reduction_log_prob_fn: ["mean", "min"]
reduction_kl_fn: ["mean", "max"]
use_schulman_kl_estimation: false
not_matched_penalty: -1.0
unbias_teacher_log_probs: true
unbias_student_log_probs_temp: 0.7

save_completions_probability: 0.1

lr_scheduler_type: "constant"
lr_scheduler_kwargs: ~

wandb_project: rl4lm_teacher
log_ctx_name: gr${num_generations}_${max_prompt_length}ctx_${max_completion_length}gen
wandb_run_name: ${trainer_log_name}

output_dir: ${results_dir}/rlt_teacher/${exp_name}

# VLLM settings (upstream-compatible)
# use_vllm: false because we're using vllm_server mode
use_vllm: false
# vLLM server mode configuration
use_vllm_server: true
vllm_host: 2dc3509b
vllm_port: 8765
num_vllm_clients: 1

# Disable model gathering during generation to avoid memory spike
ds3_gather_for_generation: false

# GRPO specific - shuffle generation inputs for load distribution
shuffle_generation_inputs: true

# Generation aggregation for efficiency
generation_aggregation_steps: 96  # Reduced proportionally from 256 for memory efficiency
